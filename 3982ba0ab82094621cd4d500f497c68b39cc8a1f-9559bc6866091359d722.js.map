{"version":3,"sources":["webpack://notebook/./node_modules/js-search/dist/esm/js-search.js","webpack://notebook/./src/utils/js-search.js","webpack://notebook/./node_modules/lodash/_Symbol.js","webpack://notebook/./node_modules/lodash/_arrayPush.js","webpack://notebook/./node_modules/lodash/_baseFlatten.js","webpack://notebook/./node_modules/lodash/_baseGetTag.js","webpack://notebook/./node_modules/lodash/_baseIsArguments.js","webpack://notebook/./node_modules/lodash/_freeGlobal.js","webpack://notebook/./node_modules/lodash/_getRawTag.js","webpack://notebook/./node_modules/lodash/_isFlattenable.js","webpack://notebook/./node_modules/lodash/_objectToString.js","webpack://notebook/./node_modules/lodash/_root.js","webpack://notebook/./node_modules/lodash/flatten.js","webpack://notebook/./node_modules/lodash/isArguments.js","webpack://notebook/./node_modules/lodash/isArray.js","webpack://notebook/./node_modules/lodash/isObjectLike.js"],"names":["PrefixIndexStrategy","prototype","expandToken","token","expandedTokens","string","i","length","charAt","push","LowerCaseSanitizer","sanitize","text","toLocaleLowerCase","trim","getNestedFieldValue","object","path","value","TfIdfSearchIndex","uidFieldName","this","_uidFieldName","_tokenToIdfCache","_tokenMap","_proto","indexDocument","uid","doc","tokenDatum","tokenMap","$numDocumentOccurrences","$totalNumOccurrences","$uidMap","uidMap","$document","$numTokenOccurrences","search","tokens","corpus","uidToDocumentMap","numTokens","tokenMetadata","j","numKeys","keys","Object","documents","calculateTfIdf","_createCalculateTfIdf","sort","documentA","documentB","_createCalculateIdf","tokenToIdfCache","numDocumentsWithToken","Math","log","calculateIdf","document","score","inverseDocumentFrequency","Infinity","Array","REGEX","SimpleTokenizer","tokenize","split","filter","_defineProperties","target","props","descriptor","enumerable","configurable","writable","defineProperty","key","Search","Error","_indexStrategy","_searchIndex","_sanitizer","_tokenizer","_documents","_searchableFields","Constructor","protoProps","staticProps","addDocument","addDocuments","concat","indexDocuments_","addIndex","field","query","_initialized","indexStrategy","sanitizer","searchIndex","tokenizer","di","numDocuments","sfi","numSearchableFields","fieldValue","searchableField","toString","fieldTokens","fti","numFieldValues","fieldToken","eti","nummExpandedTokens","expandedToken","set","get","initSearch","indexes","JsSearch","originTokenize","Boolean","map","v","segment","test","replace","forEach","index","Symbol","module","exports","array","values","offset","arrayPush","isFlattenable","baseFlatten","depth","predicate","isStrict","result","getRawTag","objectToString","symToStringTag","toStringTag","undefined","baseGetTag","isObjectLike","freeGlobal","g","objectProto","hasOwnProperty","nativeObjectToString","isOwn","call","tag","unmasked","e","isArguments","isArray","spreadableSymbol","isConcatSpreadable","freeSelf","self","root","Function","baseIsArguments","propertyIsEnumerable","arguments"],"mappings":"+JAqDIA,EAAmC,WACrC,SAASA,KAmBT,OAjBaA,EAAoBC,UAK1BC,YAAc,SAAqBC,GAIxC,IAHA,IAAIC,EAAiB,GACjBC,EAAS,GAEJC,EAAI,EAAGC,EAASJ,EAAMI,OAAQD,EAAIC,IAAUD,EACnDD,GAAUF,EAAMK,OAAOF,GACvBF,EAAeK,KAAKJ,GAGtB,OAAOD,GAGFJ,EApB8B,GA8CnCU,EAAkC,WACpC,SAASA,KAWT,OATaA,EAAmBT,UAKzBU,SAAW,SAAkBC,GAClC,OAAOA,EAAOA,EAAKC,oBAAoBC,OAAS,IAG3CJ,EAZ6B,GAuBtC,SAASK,EAAoBC,EAAQC,GACnCA,EAAOA,GAAQ,GAIf,IAFA,IAAIC,EADJF,EAASA,GAAU,GAGVV,EAAI,EAAGA,EAAIW,EAAKV,OAAQD,IAG/B,GAAa,OAFbY,EAAQA,EAAMD,EAAKX,KAGjB,OAAO,KAIX,OAAOY,EAOT,IAAIC,EAAgC,WAClC,SAASA,EAAiBC,GACxBC,KAAKC,cAAgBF,EACrBC,KAAKE,iBAAmB,GACxBF,KAAKG,UAAY,GAOnB,IAAIC,EAASN,EAAiBlB,UA+H9B,OA7HAwB,EAAOC,cAAgB,SAAuBvB,EAAOwB,EAAKC,GACxDP,KAAKE,iBAAmB,GAExB,IACIM,EADAC,EAAWT,KAAKG,UAGW,iBAApBM,EAAS3B,GAClB2B,EAAS3B,GAAS0B,EAAa,CAC7BE,wBAAyB,EACzBC,qBAAsB,EACtBC,QAAS,KAGXJ,EAAaC,EAAS3B,IACX6B,uBAGb,IAAIE,EAASL,EAAWI,QAEG,iBAAhBC,EAAOP,IAChBE,EAAWE,0BACXG,EAAOP,GAAO,CACZQ,UAAWP,EACXQ,qBAAsB,IAGxBF,EAAOP,GAAKS,wBAQhBX,EAAOY,OAAS,SAAgBC,EAAQC,GAGtC,IAFA,IAAIC,EAAmB,GAEdlC,EAAI,EAAGmC,EAAYH,EAAO/B,OAAQD,EAAImC,EAAWnC,IAAK,CAC7D,IAAIH,EAAQmC,EAAOhC,GACfoC,EAAgBrB,KAAKG,UAAUrB,GAEnC,IAAKuC,EACH,MAAO,GAGT,GAAU,IAANpC,EAGF,IAFA,IAESqC,EAAI,EAAGC,GAFZC,EAAOC,OAAOD,KAAKH,EAAcT,UAEN1B,OAAQoC,EAAIC,EAASD,IAAK,CAEvDH,EADIb,EAAMkB,EAAKF,IACSD,EAAcT,QAAQN,GAAKQ,cAGrD,KAAIU,EAEJ,IAASF,EAAI,EAAGC,GAFZC,EAAOC,OAAOD,KAAKL,IAEQjC,OAAQoC,EAAIC,EAASD,IAAK,CACvD,IAAIhB,EAAMkB,EAAKF,GAE2B,iBAA/BD,EAAcT,QAAQN,WACxBa,EAAiBb,KAMhC,IAAIoB,EAAY,GAEhB,IAAK,IAAIpB,KAAOa,EACdO,EAAUtC,KAAK+B,EAAiBb,IAGlC,IAAIqB,EAAiB3B,KAAK4B,wBAG1B,OAAOF,EAAUG,MAAK,SAAUC,EAAWC,GACzC,OAAOJ,EAAeV,EAAQc,EAAWb,GAAUS,EAAeV,EAAQa,EAAWZ,OAIzFd,EAAO4B,oBAAsB,WAC3B,IAAIvB,EAAWT,KAAKG,UAChB8B,EAAkBjC,KAAKE,iBAC3B,OAAO,SAAsBpB,EAAO4C,GAClC,IAAKO,EAAgBnD,GAAQ,CAC3B,IAAIoD,OAAmD,IAApBzB,EAAS3B,GAAyB2B,EAAS3B,GAAO4B,wBAA0B,EAC/GuB,EAAgBnD,GAAS,EAAIqD,KAAKC,IAAIV,EAAUxC,QAAU,EAAIgD,IAGhE,OAAOD,EAAgBnD,KAI3BsB,EAAOwB,sBAAwB,WAC7B,IAAInB,EAAWT,KAAKG,UAChBJ,EAAeC,KAAKC,cAEpBoC,EAAerC,KAAKgC,sBAExB,OAAO,SAAwBf,EAAQqB,EAAUZ,GAG/C,IAFA,IAAIa,EAAQ,EAEHtD,EAAI,EAAGmC,EAAYH,EAAO/B,OAAQD,EAAImC,IAAanC,EAAG,CAC7D,IAOIqB,EAPAxB,EAAQmC,EAAOhC,GACfuD,EAA2BH,EAAavD,EAAO4C,GAE/Cc,IAA6BC,MAC/BD,EAA2B,GAM3BlC,EADEP,aAAwB2C,MACpBJ,GAAY5C,EAAoB4C,EAAUvC,GAE1CuC,GAAYA,EAASvC,GAI7BwC,SAD+C,IAApB9B,EAAS3B,SAAkE,IAAjC2B,EAAS3B,GAAO8B,QAAQN,GAAuBG,EAAS3B,GAAO8B,QAAQN,GAAKS,qBAAuB,GAC/IyB,EAG3B,OAAOD,IAIJzC,EA1I2B,GAsNhC6C,EAAQ,qBAKRC,EAA+B,WACjC,SAASA,KAcT,OAZaA,EAAgBhE,UAKtBiE,SAAW,SAAkBtD,GAClC,OAAOA,EAAKuD,MAAMH,GAAOI,QAAO,SAAUxD,GACxC,OAAOA,MAKJqD,EAf0B,GAyNnC,SAASI,EAAkBC,EAAQC,GACjC,IAAK,IAAIjE,EAAI,EAAGA,EAAIiE,EAAMhE,OAAQD,IAAK,CACrC,IAAIkE,EAAaD,EAAMjE,GACvBkE,EAAWC,WAAaD,EAAWC,aAAc,EACjDD,EAAWE,cAAe,EACtB,UAAWF,IAAYA,EAAWG,UAAW,GACjD7B,OAAO8B,eAAeN,EAAQE,EAAWK,IAAKL,IAgBlD,IAAIM,EAAsB,WAUxB,SAASA,EAAO1D,GACd,IAAKA,EACH,MAAM2D,MAAM,6DAGd1D,KAAKC,cAAgBF,EAErBC,KAAK2D,eAAiB,IAAIhF,EAC1BqB,KAAK4D,aAAe,IAAI9D,EAAiBC,GACzCC,KAAK6D,WAAa,IAAIxE,EACtBW,KAAK8D,WAAa,IAAIlB,EACtB5C,KAAK+D,WAAa,GAClB/D,KAAKgE,kBAAoB,GAS3B,IA3CoBC,EAAaC,EAAYC,EA2CzC/D,EAASqD,EAAO7E,UAuKpB,OAjKAwB,EAAOgE,YAAc,SAAqB9B,GACxCtC,KAAKqE,aAAa,CAAC/B,KAQrBlC,EAAOiE,aAAe,SAAsB3C,GAC1C1B,KAAK+D,WAAa/D,KAAK+D,WAAWO,OAAO5C,GACzC1B,KAAKuE,gBAAgB7C,EAAW1B,KAAKgE,oBASvC5D,EAAOoE,SAAW,SAAkBC,GAClCzE,KAAKgE,kBAAkB5E,KAAKqF,GAE5BzE,KAAKuE,gBAAgBvE,KAAK+D,WAAY,CAACU,KASzCrE,EAAOY,OAAS,SAAgB0D,GAC9B,IAAIzD,EAASjB,KAAK8D,WAAWjB,SAAS7C,KAAK6D,WAAWvE,SAASoF,IAE/D,OAAO1E,KAAK4D,aAAa5C,OAAOC,EAAQjB,KAAK+D,aAS/C3D,EAAOmE,gBAAkB,SAAyB7C,EAAWsC,GAC3DhE,KAAK2E,cAAe,EAOpB,IANA,IAAIC,EAAgB5E,KAAK2D,eACrBkB,EAAY7E,KAAK6D,WACjBiB,EAAc9E,KAAK4D,aACnBmB,EAAY/E,KAAK8D,WACjB/D,EAAeC,KAAKC,cAEf+E,EAAK,EAAGC,EAAevD,EAAUxC,OAAQ8F,EAAKC,EAAcD,IAAM,CACzE,IACI1E,EADAC,EAAMmB,EAAUsD,GAIlB1E,EADEP,aAAwB2C,MACpBhD,EAAoBa,EAAKR,GAEzBQ,EAAIR,GAGZ,IAAK,IAAImF,EAAM,EAAGC,EAAsBnB,EAAkB9E,OAAQgG,EAAMC,EAAqBD,IAAO,CAClG,IAAIE,EACAC,EAAkBrB,EAAkBkB,GAYxC,GAJkB,OALhBE,EADEC,aAA2B3C,MAChBhD,EAAoBa,EAAK8E,GAEzB9E,EAAI8E,KAG6B,iBAAfD,GAA2BA,EAAWE,WACrEF,EAAaA,EAAWE,YAGA,iBAAfF,EAGT,IAFA,IAAIG,EAAcR,EAAUlC,SAASgC,EAAUvF,SAAS8F,IAE/CI,EAAM,EAAGC,EAAiBF,EAAYrG,OAAQsG,EAAMC,EAAgBD,IAI3E,IAHA,IAAIE,EAAaH,EAAYC,GACzBzG,EAAiB6F,EAAc/F,YAAY6G,GAEtCC,EAAM,EAAGC,EAAqB7G,EAAeG,OAAQyG,EAAMC,EAAoBD,IAAO,CAC7F,IAAIE,EAAgB9G,EAAe4G,GACnCb,EAAYzE,cAAcwF,EAAevF,EAAKC,OAtItC0D,EA8IPR,GA9IoBS,EA8IZ,CAAC,CACpBV,IAAK,gBACLsC,IAAK,SAAajG,GAChB,GAAIG,KAAK2E,aACP,MAAMjB,MAAM,qDAGd1D,KAAK2D,eAAiB9D,GAExBkG,IAAK,WACH,OAAO/F,KAAK2D,iBAQb,CACDH,IAAK,YACLsC,IAAK,SAAajG,GAChB,GAAIG,KAAK2E,aACP,MAAMjB,MAAM,iDAGd1D,KAAK6D,WAAahE,GAEpBkG,IAAK,WACH,OAAO/F,KAAK6D,aAQb,CACDL,IAAK,cACLsC,IAAK,SAAajG,GAChB,GAAIG,KAAK2E,aACP,MAAMjB,MAAM,mDAGd1D,KAAK4D,aAAe/D,GAEtBkG,IAAK,WACH,OAAO/F,KAAK4D,eAQb,CACDJ,IAAK,YACLsC,IAAK,SAAajG,GAChB,GAAIG,KAAK2E,aACP,MAAMjB,MAAM,iDAGd1D,KAAK8D,WAAajE,GAEpBkG,IAAK,WACH,OAAO/F,KAAK8D,gBA7MAd,EAAkBiB,EAAYrF,UAAWsF,GACrDC,GAAanB,EAAkBiB,EAAaE,GAgNzCV,EAtMiB,GCrlBnB,SAASuC,EAAW1F,EAAK2F,EAASvE,GACvC,IAAMV,EAAS,IAAIkF,EAAgB5F,GAE7B6F,EAAiBnF,EAAO+D,UAAUlC,SAwBxC,OAtBA7B,EAAO+D,UAAUlC,SAAW,SAAStD,GACnC,OAAO,IACL,IACEA,EAAKuD,MAAM,KACRC,OAAOqD,SACPC,KAAI,SAAAC,GAAC,OAAIA,EAAExD,MAAM,WACpBuD,KAAI,SAACE,GAGL,MAFc,gCAEJC,KAAKD,GACNJ,EAAeI,GAGjBA,EAAQE,QAAQ,eAAgB,IAAI3D,MAAM,SAKvDmD,EAAQS,SAAQ,SAAAC,GAAK,OAAI3F,EAAOwD,SAASmC,MAEzC3F,EAAOqD,aAAa3C,GAEbV,I,qBC9BT,IAGI4F,EAHO,EAAQ,MAGDA,OAElBC,EAAOC,QAAUF,G,iBCcjBC,EAAOC,QAXP,SAAmBC,EAAOC,GAKxB,IAJA,IAAIL,GAAS,EACTzH,EAAS8H,EAAO9H,OAChB+H,EAASF,EAAM7H,SAEVyH,EAAQzH,GACf6H,EAAME,EAASN,GAASK,EAAOL,GAEjC,OAAOI,I,qBChBT,IAAIG,EAAY,EAAQ,MACpBC,EAAgB,EAAQ,MAoC5BN,EAAOC,QAvBP,SAASM,EAAYL,EAAOM,EAAOC,EAAWC,EAAUC,GACtD,IAAIb,GAAS,EACTzH,EAAS6H,EAAM7H,OAKnB,IAHAoI,IAAcA,EAAYH,GAC1BK,IAAWA,EAAS,MAEXb,EAAQzH,GAAQ,CACvB,IAAIW,EAAQkH,EAAMJ,GACdU,EAAQ,GAAKC,EAAUzH,GACrBwH,EAAQ,EAEVD,EAAYvH,EAAOwH,EAAQ,EAAGC,EAAWC,EAAUC,GAEnDN,EAAUM,EAAQ3H,GAEV0H,IACVC,EAAOA,EAAOtI,QAAUW,GAG5B,OAAO2H,I,qBClCT,IAAIZ,EAAS,EAAQ,MACjBa,EAAY,EAAQ,MACpBC,EAAiB,EAAQ,MAOzBC,EAAiBf,EAASA,EAAOgB,iBAAcC,EAkBnDhB,EAAOC,QATP,SAAoBjH,GAClB,OAAa,MAATA,OACegI,IAAVhI,EAdQ,qBADL,gBAiBJ8H,GAAkBA,KAAkBlG,OAAO5B,GAC/C4H,EAAU5H,GACV6H,EAAe7H,K,qBCxBrB,IAAIiI,EAAa,EAAQ,MACrBC,EAAe,EAAQ,MAgB3BlB,EAAOC,QAJP,SAAyBjH,GACvB,OAAOkI,EAAalI,IAVR,sBAUkBiI,EAAWjI,K,qBCb3C,IAAImI,EAA8B,iBAAV,EAAAC,GAAsB,EAAAA,GAAU,EAAAA,EAAOxG,SAAWA,QAAU,EAAAwG,EAEpFpB,EAAOC,QAAUkB,G,qBCHjB,IAAIpB,EAAS,EAAQ,MAGjBsB,EAAczG,OAAO7C,UAGrBuJ,EAAiBD,EAAYC,eAO7BC,EAAuBF,EAAY5C,SAGnCqC,EAAiBf,EAASA,EAAOgB,iBAAcC,EA6BnDhB,EAAOC,QApBP,SAAmBjH,GACjB,IAAIwI,EAAQF,EAAeG,KAAKzI,EAAO8H,GACnCY,EAAM1I,EAAM8H,GAEhB,IACE9H,EAAM8H,QAAkBE,EACxB,IAAIW,GAAW,EACf,MAAOC,IAET,IAAIjB,EAASY,EAAqBE,KAAKzI,GAQvC,OAPI2I,IACEH,EACFxI,EAAM8H,GAAkBY,SAEjB1I,EAAM8H,IAGVH,I,qBC1CT,IAAIZ,EAAS,EAAQ,MACjB8B,EAAc,EAAQ,MACtBC,EAAU,EAAQ,MAGlBC,EAAmBhC,EAASA,EAAOiC,wBAAqBhB,EAc5DhB,EAAOC,QALP,SAAuBjH,GACrB,OAAO8I,EAAQ9I,IAAU6I,EAAY7I,OAChC+I,GAAoB/I,GAASA,EAAM+I,M,iBCf1C,IAOIR,EAPc3G,OAAO7C,UAOc0G,SAavCuB,EAAOC,QAJP,SAAwBjH,GACtB,OAAOuI,EAAqBE,KAAKzI,K,qBClBnC,IAAImI,EAAa,EAAQ,MAGrBc,EAA0B,iBAARC,MAAoBA,MAAQA,KAAKtH,SAAWA,QAAUsH,KAGxEC,EAAOhB,GAAcc,GAAYG,SAAS,cAATA,GAErCpC,EAAOC,QAAUkC,G,qBCRjB,IAAI5B,EAAc,EAAQ,MAqB1BP,EAAOC,QALP,SAAiBC,GAEf,OADsB,MAATA,EAAgB,EAAIA,EAAM7H,QACvBkI,EAAYL,EAAO,GAAK,K,qBClB1C,IAAImC,EAAkB,EAAQ,MAC1BnB,EAAe,EAAQ,MAGvBG,EAAczG,OAAO7C,UAGrBuJ,EAAiBD,EAAYC,eAG7BgB,EAAuBjB,EAAYiB,qBAoBnCT,EAAcQ,EAAgB,WAAa,OAAOE,UAApB,IAAsCF,EAAkB,SAASrJ,GACjG,OAAOkI,EAAalI,IAAUsI,EAAeG,KAAKzI,EAAO,YACtDsJ,EAAqBb,KAAKzI,EAAO,WAGtCgH,EAAOC,QAAU4B,G,iBCZjB,IAAIC,EAAUjG,MAAMiG,QAEpB9B,EAAOC,QAAU6B,G,iBCGjB9B,EAAOC,QAJP,SAAsBjH,GACpB,OAAgB,MAATA,GAAiC,iBAATA","file":"3982ba0ab82094621cd4d500f497c68b39cc8a1f-9559bc6866091359d722.js","sourcesContent":["/**\n * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n */\nvar AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n  function AllSubstringsIndexStrategy() {}\n\n  var _proto = AllSubstringsIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string;\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string = '';\n\n      for (var j = i; j < length; ++j) {\n        string += token.charAt(j);\n        expandedTokens.push(string);\n      }\n    }\n\n    return expandedTokens;\n  };\n\n  return AllSubstringsIndexStrategy;\n}();\n/**\n * Indexes for exact word matches.\n */\n\n\nvar ExactWordIndexStrategy = /*#__PURE__*/function () {\n  function ExactWordIndexStrategy() {}\n\n  var _proto = ExactWordIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    return token ? [token] : [];\n  };\n\n  return ExactWordIndexStrategy;\n}();\n/**\n * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n */\n\n\nvar PrefixIndexStrategy = /*#__PURE__*/function () {\n  function PrefixIndexStrategy() {}\n\n  var _proto = PrefixIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string = '';\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string += token.charAt(i);\n      expandedTokens.push(string);\n    }\n\n    return expandedTokens;\n  };\n\n  return PrefixIndexStrategy;\n}();\n/**\n * Enforces case-sensitive text matches.\n */\n\n\nvar CaseSensitiveSanitizer = /*#__PURE__*/function () {\n  function CaseSensitiveSanitizer() {}\n\n  var _proto = CaseSensitiveSanitizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.trim() : '';\n  };\n\n  return CaseSensitiveSanitizer;\n}();\n/**\n * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n */\n\n\nvar LowerCaseSanitizer = /*#__PURE__*/function () {\n  function LowerCaseSanitizer() {}\n\n  var _proto = LowerCaseSanitizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.toLocaleLowerCase().trim() : '';\n  };\n\n  return LowerCaseSanitizer;\n}();\n/**\n * Find and return a nested object value.\n *\n * @param object to crawl\n * @param path Property path\n * @returns {any}\n */\n\n\nfunction getNestedFieldValue(object, path) {\n  path = path || [];\n  object = object || {};\n  var value = object; // walk down the property path\n\n  for (var i = 0; i < path.length; i++) {\n    value = value[path[i]];\n\n    if (value == null) {\n      return null;\n    }\n  }\n\n  return value;\n}\n/**\n * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n */\n\n\nvar TfIdfSearchIndex = /*#__PURE__*/function () {\n  function TfIdfSearchIndex(uidFieldName) {\n    this._uidFieldName = uidFieldName;\n    this._tokenToIdfCache = {};\n    this._tokenMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = TfIdfSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n    var tokenMap = this._tokenMap;\n    var tokenDatum;\n\n    if (typeof tokenMap[token] !== 'object') {\n      tokenMap[token] = tokenDatum = {\n        $numDocumentOccurrences: 0,\n        $totalNumOccurrences: 1,\n        $uidMap: {}\n      };\n    } else {\n      tokenDatum = tokenMap[token];\n      tokenDatum.$totalNumOccurrences++;\n    }\n\n    var uidMap = tokenDatum.$uidMap;\n\n    if (typeof uidMap[uid] !== 'object') {\n      tokenDatum.$numDocumentOccurrences++;\n      uidMap[uid] = {\n        $document: doc,\n        $numTokenOccurrences: 1\n      };\n    } else {\n      uidMap[uid].$numTokenOccurrences++;\n    }\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var uidToDocumentMap = {};\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!tokenMetadata) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(tokenMetadata.$uidMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n        }\n      } else {\n        var keys = Object.keys(uidToDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n            delete uidToDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var documents = [];\n\n    for (var uid in uidToDocumentMap) {\n      documents.push(uidToDocumentMap[uid]);\n    }\n\n    var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n    return documents.sort(function (documentA, documentB) {\n      return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n    });\n  };\n\n  _proto._createCalculateIdf = function _createCalculateIdf() {\n    var tokenMap = this._tokenMap;\n    var tokenToIdfCache = this._tokenToIdfCache;\n    return function calculateIdf(token, documents) {\n      if (!tokenToIdfCache[token]) {\n        var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n        tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n      }\n\n      return tokenToIdfCache[token];\n    };\n  };\n\n  _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n    var tokenMap = this._tokenMap;\n    var uidFieldName = this._uidFieldName;\n\n    var calculateIdf = this._createCalculateIdf();\n\n    return function calculateTfIdf(tokens, document, documents) {\n      var score = 0;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n        var token = tokens[i];\n        var inverseDocumentFrequency = calculateIdf(token, documents);\n\n        if (inverseDocumentFrequency === Infinity) {\n          inverseDocumentFrequency = 0;\n        }\n\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = document && getNestedFieldValue(document, uidFieldName);\n        } else {\n          uid = document && document[uidFieldName];\n        }\n\n        var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n        score += termFrequency * inverseDocumentFrequency;\n      }\n\n      return score;\n    };\n  };\n\n  return TfIdfSearchIndex;\n}();\n/**\n * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n */\n\n\nvar UnorderedSearchIndex = /*#__PURE__*/function () {\n  function UnorderedSearchIndex() {\n    this._tokenToUidToDocumentMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = UnorderedSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n      this._tokenToUidToDocumentMap[token] = {};\n    }\n\n    this._tokenToUidToDocumentMap[token][uid] = doc;\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var intersectingDocumentMap = {};\n    var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!documentMap) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(documentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          intersectingDocumentMap[uid] = documentMap[uid];\n        }\n      } else {\n        var keys = Object.keys(intersectingDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof documentMap[uid] !== 'object') {\n            delete intersectingDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var keys = Object.keys(intersectingDocumentMap);\n    var documents = [];\n\n    for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n      var uid = keys[i];\n      documents.push(intersectingDocumentMap[uid]);\n    }\n\n    return documents;\n  };\n\n  return UnorderedSearchIndex;\n}();\n\nvar REGEX = /[^a-zа-яё0-9\\-']+/i;\n/**\n * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n */\n\nvar SimpleTokenizer = /*#__PURE__*/function () {\n  function SimpleTokenizer() {}\n\n  var _proto = SimpleTokenizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.tokenize = function tokenize(text) {\n    return text.split(REGEX).filter(function (text) {\n      return text;\n    } // Filter empty tokens\n    );\n  };\n\n  return SimpleTokenizer;\n}();\n/**\n * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n *\n * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n *\n * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n */\n\n\nvar StemmingTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param stemmingFunction Function capable of accepting a word and returning its stem.\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n    this._stemmingFunction = stemmingFunction;\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StemmingTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n  };\n\n  return StemmingTokenizer;\n}();\n/**\n * Stop words list copied from Lunr JS.\n */\n\n\nvar StopWordsMap = {\n  a: true,\n  able: true,\n  about: true,\n  across: true,\n  after: true,\n  all: true,\n  almost: true,\n  also: true,\n  am: true,\n  among: true,\n  an: true,\n  and: true,\n  any: true,\n  are: true,\n  as: true,\n  at: true,\n  be: true,\n  because: true,\n  been: true,\n  but: true,\n  by: true,\n  can: true,\n  cannot: true,\n  could: true,\n  dear: true,\n  did: true,\n  'do': true,\n  does: true,\n  either: true,\n  'else': true,\n  ever: true,\n  every: true,\n  'for': true,\n  from: true,\n  'get': true,\n  got: true,\n  had: true,\n  has: true,\n  have: true,\n  he: true,\n  her: true,\n  hers: true,\n  him: true,\n  his: true,\n  how: true,\n  however: true,\n  i: true,\n  'if': true,\n  'in': true,\n  into: true,\n  is: true,\n  it: true,\n  its: true,\n  just: true,\n  least: true,\n  \"let\": true,\n  like: true,\n  likely: true,\n  may: true,\n  me: true,\n  might: true,\n  most: true,\n  must: true,\n  my: true,\n  neither: true,\n  no: true,\n  nor: true,\n  not: true,\n  of: true,\n  off: true,\n  often: true,\n  on: true,\n  only: true,\n  or: true,\n  other: true,\n  our: true,\n  own: true,\n  rather: true,\n  said: true,\n  say: true,\n  says: true,\n  she: true,\n  should: true,\n  since: true,\n  so: true,\n  some: true,\n  than: true,\n  that: true,\n  the: true,\n  their: true,\n  them: true,\n  then: true,\n  there: true,\n  these: true,\n  they: true,\n  'this': true,\n  tis: true,\n  to: true,\n  too: true,\n  twas: true,\n  us: true,\n  wants: true,\n  was: true,\n  we: true,\n  were: true,\n  what: true,\n  when: true,\n  where: true,\n  which: true,\n  'while': true,\n  who: true,\n  whom: true,\n  why: true,\n  will: true,\n  'with': true,\n  would: true,\n  yet: true,\n  you: true,\n  your: true\n}; // Prevent false positives for inherited properties\n\nStopWordsMap.constructor = false;\nStopWordsMap.hasOwnProperty = false;\nStopWordsMap.isPrototypeOf = false;\nStopWordsMap.propertyIsEnumerable = false;\nStopWordsMap.toLocaleString = false;\nStopWordsMap.toString = false;\nStopWordsMap.valueOf = false;\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\nvar StopWordsTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StopWordsTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).filter(function (token) {\n      return !StopWordsMap[token];\n    });\n  };\n\n  return StopWordsTokenizer;\n}();\n\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n/**\n * Simple client-side searching within a set of documents.\n *\n * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n */\n\n\nvar Search = /*#__PURE__*/function () {\n  /**\n   * Array containing either a property name or a path (list of property names) to a nested value\n   */\n\n  /**\n   * Constructor.\n   * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n   *                     to ensure that a search result set does not contain duplicate objects.\n   */\n  function Search(uidFieldName) {\n    if (!uidFieldName) {\n      throw Error('js-search requires a uid field name constructor parameter');\n    }\n\n    this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n    this._indexStrategy = new PrefixIndexStrategy();\n    this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n    this._sanitizer = new LowerCaseSanitizer();\n    this._tokenizer = new SimpleTokenizer();\n    this._documents = [];\n    this._searchableFields = [];\n  }\n  /**\n   * Override the default index strategy.\n   * @param value Custom index strategy\n   * @throws Error if documents have already been indexed by this search instance\n   */\n\n\n  var _proto = Search.prototype;\n  /**\n   * Add a searchable document to the index. Document will automatically be indexed for search.\n   * @param document\n   */\n\n  _proto.addDocument = function addDocument(document) {\n    this.addDocuments([document]);\n  }\n  /**\n   * Adds searchable documents to the index. Documents will automatically be indexed for search.\n   * @param document\n   */\n  ;\n\n  _proto.addDocuments = function addDocuments(documents) {\n    this._documents = this._documents.concat(documents);\n    this.indexDocuments_(documents, this._searchableFields);\n  }\n  /**\n   * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n   *\n   * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n   */\n  ;\n\n  _proto.addIndex = function addIndex(field) {\n    this._searchableFields.push(field);\n\n    this.indexDocuments_(this._documents, [field]);\n  }\n  /**\n   * Search all documents for ones matching the specified query text.\n   * @param query\n   * @returns {Array<Object>}\n   */\n  ;\n\n  _proto.search = function search(query) {\n    var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n    return this._searchIndex.search(tokens, this._documents);\n  }\n  /**\n   * @param documents\n   * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n   * @private\n   */\n  ;\n\n  _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n    this._initialized = true;\n    var indexStrategy = this._indexStrategy;\n    var sanitizer = this._sanitizer;\n    var searchIndex = this._searchIndex;\n    var tokenizer = this._tokenizer;\n    var uidFieldName = this._uidFieldName;\n\n    for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n      var doc = documents[di];\n      var uid;\n\n      if (uidFieldName instanceof Array) {\n        uid = getNestedFieldValue(doc, uidFieldName);\n      } else {\n        uid = doc[uidFieldName];\n      }\n\n      for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n        var fieldValue;\n        var searchableField = _searchableFields[sfi];\n\n        if (searchableField instanceof Array) {\n          fieldValue = getNestedFieldValue(doc, searchableField);\n        } else {\n          fieldValue = doc[searchableField];\n        }\n\n        if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n          fieldValue = fieldValue.toString();\n        }\n\n        if (typeof fieldValue === 'string') {\n          var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n          for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n            var fieldToken = fieldTokens[fti];\n            var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n            for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n              var expandedToken = expandedTokens[eti];\n              searchIndex.indexDocument(expandedToken, uid, doc);\n            }\n          }\n        }\n      }\n    }\n  };\n\n  _createClass(Search, [{\n    key: \"indexStrategy\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('IIndexStrategy cannot be set after initialization');\n      }\n\n      this._indexStrategy = value;\n    },\n    get: function get() {\n      return this._indexStrategy;\n    }\n    /**\n     * Override the default text sanitizing strategy.\n     * @param value Custom text sanitizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"sanitizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISanitizer cannot be set after initialization');\n      }\n\n      this._sanitizer = value;\n    },\n    get: function get() {\n      return this._sanitizer;\n    }\n    /**\n     * Override the default search index strategy.\n     * @param value Custom search index strategy\n     * @throws Error if documents have already been indexed\n     */\n\n  }, {\n    key: \"searchIndex\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISearchIndex cannot be set after initialization');\n      }\n\n      this._searchIndex = value;\n    },\n    get: function get() {\n      return this._searchIndex;\n    }\n    /**\n     * Override the default text tokenizing strategy.\n     * @param value Custom text tokenizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"tokenizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ITokenizer cannot be set after initialization');\n      }\n\n      this._tokenizer = value;\n    },\n    get: function get() {\n      return this._tokenizer;\n    }\n  }]);\n\n  return Search;\n}();\n/**\n * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n * of match criteria within searchable fields.\n *\n * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n */\n\n\nvar TokenHighlighter = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param opt_indexStrategy Index strategy used by Search\n   * @param opt_sanitizer Sanitizer used by Search\n   * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n   */\n  function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n    this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n    this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n    this._wrapperTagName = opt_wrapperTagName || 'mark';\n  }\n  /**\n   * Highlights token occurrences within a string by wrapping them with a DOM element.\n   *\n   * @param text e.g. \"john wayne\"\n   * @param tokens e.g. [\"wa\"]\n   * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n   */\n\n\n  var _proto = TokenHighlighter.prototype;\n\n  _proto.highlight = function highlight(text, tokens) {\n    var tagsLength = this._wrapText('').length;\n\n    var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = this._sanitizer.sanitize(tokens[i]);\n\n      var expandedTokens = this._indexStrategy.expandToken(token);\n\n      for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n        var expandedToken = expandedTokens[j];\n\n        if (!tokenDictionary[expandedToken]) {\n          tokenDictionary[expandedToken] = [token];\n        } else {\n          tokenDictionary[expandedToken].push(token);\n        }\n      }\n    } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n    var actualCurrentWord = '';\n    var sanitizedCurrentWord = '';\n    var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n    for (var i = 0, textLength = text.length; i < textLength; i++) {\n      var character = text.charAt(i);\n\n      if (character === ' ') {\n        actualCurrentWord = '';\n        sanitizedCurrentWord = '';\n        currentWordStartIndex = i + 1;\n      } else {\n        actualCurrentWord += character;\n        sanitizedCurrentWord += this._sanitizer.sanitize(character);\n      }\n\n      if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n        actualCurrentWord = this._wrapText(actualCurrentWord);\n        text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n        i += tagsLength;\n        textLength += tagsLength;\n      }\n    }\n\n    return text;\n  }\n  /**\n   * @param text to wrap\n   * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n   * @private\n   */\n  ;\n\n  _proto._wrapText = function _wrapText(text) {\n    var tagName = this._wrapperTagName;\n    return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n  };\n\n  return TokenHighlighter;\n}();\n\nexport { AllSubstringsIndexStrategy, CaseSensitiveSanitizer, ExactWordIndexStrategy, LowerCaseSanitizer, PrefixIndexStrategy, Search, SimpleTokenizer, StemmingTokenizer, StopWordsMap, StopWordsTokenizer, TfIdfSearchIndex, TokenHighlighter, UnorderedSearchIndex };","import { flatten } from 'lodash'\nimport * as JsSearch from 'js-search'\n\nexport function initSearch(uid, indexes, documents) {\n  const search = new JsSearch.Search(uid)\n\n  const originTokenize = search.tokenizer.tokenize\n\n  search.tokenizer.tokenize = function(text) {\n    return flatten(\n      flatten(\n        text.split('/')\n          .filter(Boolean)\n          .map(v => v.split(/\\s+/)),\n      ).map((segment) => {\n        const enReg = /^[a-zA-Z0-9$@$!%*?&#^-_. +]+$/\n\n        if (enReg.test(segment)) {\n          return originTokenize(segment)\n        }\n\n        return segment.replace(/[\\x00-\\x7F]/g, \"\").split('')\n      })\n    )\n  }\n\n  indexes.forEach(index => search.addIndex(index))\n\n  search.addDocuments(documents)\n\n  return search\n}\n","var root = require('./_root');\n\n/** Built-in value references. */\nvar Symbol = root.Symbol;\n\nmodule.exports = Symbol;\n","/**\n * Appends the elements of `values` to `array`.\n *\n * @private\n * @param {Array} array The array to modify.\n * @param {Array} values The values to append.\n * @returns {Array} Returns `array`.\n */\nfunction arrayPush(array, values) {\n  var index = -1,\n      length = values.length,\n      offset = array.length;\n\n  while (++index < length) {\n    array[offset + index] = values[index];\n  }\n  return array;\n}\n\nmodule.exports = arrayPush;\n","var arrayPush = require('./_arrayPush'),\n    isFlattenable = require('./_isFlattenable');\n\n/**\n * The base implementation of `_.flatten` with support for restricting flattening.\n *\n * @private\n * @param {Array} array The array to flatten.\n * @param {number} depth The maximum recursion depth.\n * @param {boolean} [predicate=isFlattenable] The function invoked per iteration.\n * @param {boolean} [isStrict] Restrict to values that pass `predicate` checks.\n * @param {Array} [result=[]] The initial result value.\n * @returns {Array} Returns the new flattened array.\n */\nfunction baseFlatten(array, depth, predicate, isStrict, result) {\n  var index = -1,\n      length = array.length;\n\n  predicate || (predicate = isFlattenable);\n  result || (result = []);\n\n  while (++index < length) {\n    var value = array[index];\n    if (depth > 0 && predicate(value)) {\n      if (depth > 1) {\n        // Recursively flatten arrays (susceptible to call stack limits).\n        baseFlatten(value, depth - 1, predicate, isStrict, result);\n      } else {\n        arrayPush(result, value);\n      }\n    } else if (!isStrict) {\n      result[result.length] = value;\n    }\n  }\n  return result;\n}\n\nmodule.exports = baseFlatten;\n","var Symbol = require('./_Symbol'),\n    getRawTag = require('./_getRawTag'),\n    objectToString = require('./_objectToString');\n\n/** `Object#toString` result references. */\nvar nullTag = '[object Null]',\n    undefinedTag = '[object Undefined]';\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * The base implementation of `getTag` without fallbacks for buggy environments.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the `toStringTag`.\n */\nfunction baseGetTag(value) {\n  if (value == null) {\n    return value === undefined ? undefinedTag : nullTag;\n  }\n  return (symToStringTag && symToStringTag in Object(value))\n    ? getRawTag(value)\n    : objectToString(value);\n}\n\nmodule.exports = baseGetTag;\n","var baseGetTag = require('./_baseGetTag'),\n    isObjectLike = require('./isObjectLike');\n\n/** `Object#toString` result references. */\nvar argsTag = '[object Arguments]';\n\n/**\n * The base implementation of `_.isArguments`.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n */\nfunction baseIsArguments(value) {\n  return isObjectLike(value) && baseGetTag(value) == argsTag;\n}\n\nmodule.exports = baseIsArguments;\n","/** Detect free variable `global` from Node.js. */\nvar freeGlobal = typeof global == 'object' && global && global.Object === Object && global;\n\nmodule.exports = freeGlobal;\n","var Symbol = require('./_Symbol');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/** Built-in value references. */\nvar symToStringTag = Symbol ? Symbol.toStringTag : undefined;\n\n/**\n * A specialized version of `baseGetTag` which ignores `Symbol.toStringTag` values.\n *\n * @private\n * @param {*} value The value to query.\n * @returns {string} Returns the raw `toStringTag`.\n */\nfunction getRawTag(value) {\n  var isOwn = hasOwnProperty.call(value, symToStringTag),\n      tag = value[symToStringTag];\n\n  try {\n    value[symToStringTag] = undefined;\n    var unmasked = true;\n  } catch (e) {}\n\n  var result = nativeObjectToString.call(value);\n  if (unmasked) {\n    if (isOwn) {\n      value[symToStringTag] = tag;\n    } else {\n      delete value[symToStringTag];\n    }\n  }\n  return result;\n}\n\nmodule.exports = getRawTag;\n","var Symbol = require('./_Symbol'),\n    isArguments = require('./isArguments'),\n    isArray = require('./isArray');\n\n/** Built-in value references. */\nvar spreadableSymbol = Symbol ? Symbol.isConcatSpreadable : undefined;\n\n/**\n * Checks if `value` is a flattenable `arguments` object or array.\n *\n * @private\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is flattenable, else `false`.\n */\nfunction isFlattenable(value) {\n  return isArray(value) || isArguments(value) ||\n    !!(spreadableSymbol && value && value[spreadableSymbol]);\n}\n\nmodule.exports = isFlattenable;\n","/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/**\n * Used to resolve the\n * [`toStringTag`](http://ecma-international.org/ecma-262/7.0/#sec-object.prototype.tostring)\n * of values.\n */\nvar nativeObjectToString = objectProto.toString;\n\n/**\n * Converts `value` to a string using `Object.prototype.toString`.\n *\n * @private\n * @param {*} value The value to convert.\n * @returns {string} Returns the converted string.\n */\nfunction objectToString(value) {\n  return nativeObjectToString.call(value);\n}\n\nmodule.exports = objectToString;\n","var freeGlobal = require('./_freeGlobal');\n\n/** Detect free variable `self`. */\nvar freeSelf = typeof self == 'object' && self && self.Object === Object && self;\n\n/** Used as a reference to the global object. */\nvar root = freeGlobal || freeSelf || Function('return this')();\n\nmodule.exports = root;\n","var baseFlatten = require('./_baseFlatten');\n\n/**\n * Flattens `array` a single level deep.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Array\n * @param {Array} array The array to flatten.\n * @returns {Array} Returns the new flattened array.\n * @example\n *\n * _.flatten([1, [2, [3, [4]], 5]]);\n * // => [1, 2, [3, [4]], 5]\n */\nfunction flatten(array) {\n  var length = array == null ? 0 : array.length;\n  return length ? baseFlatten(array, 1) : [];\n}\n\nmodule.exports = flatten;\n","var baseIsArguments = require('./_baseIsArguments'),\n    isObjectLike = require('./isObjectLike');\n\n/** Used for built-in method references. */\nvar objectProto = Object.prototype;\n\n/** Used to check objects for own properties. */\nvar hasOwnProperty = objectProto.hasOwnProperty;\n\n/** Built-in value references. */\nvar propertyIsEnumerable = objectProto.propertyIsEnumerable;\n\n/**\n * Checks if `value` is likely an `arguments` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an `arguments` object,\n *  else `false`.\n * @example\n *\n * _.isArguments(function() { return arguments; }());\n * // => true\n *\n * _.isArguments([1, 2, 3]);\n * // => false\n */\nvar isArguments = baseIsArguments(function() { return arguments; }()) ? baseIsArguments : function(value) {\n  return isObjectLike(value) && hasOwnProperty.call(value, 'callee') &&\n    !propertyIsEnumerable.call(value, 'callee');\n};\n\nmodule.exports = isArguments;\n","/**\n * Checks if `value` is classified as an `Array` object.\n *\n * @static\n * @memberOf _\n * @since 0.1.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is an array, else `false`.\n * @example\n *\n * _.isArray([1, 2, 3]);\n * // => true\n *\n * _.isArray(document.body.children);\n * // => false\n *\n * _.isArray('abc');\n * // => false\n *\n * _.isArray(_.noop);\n * // => false\n */\nvar isArray = Array.isArray;\n\nmodule.exports = isArray;\n","/**\n * Checks if `value` is object-like. A value is object-like if it's not `null`\n * and has a `typeof` result of \"object\".\n *\n * @static\n * @memberOf _\n * @since 4.0.0\n * @category Lang\n * @param {*} value The value to check.\n * @returns {boolean} Returns `true` if `value` is object-like, else `false`.\n * @example\n *\n * _.isObjectLike({});\n * // => true\n *\n * _.isObjectLike([1, 2, 3]);\n * // => true\n *\n * _.isObjectLike(_.noop);\n * // => false\n *\n * _.isObjectLike(null);\n * // => false\n */\nfunction isObjectLike(value) {\n  return value != null && typeof value == 'object';\n}\n\nmodule.exports = isObjectLike;\n"],"sourceRoot":""}